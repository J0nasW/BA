%
% ****
\chapter*{Abstract und Kurzfassung}
\addcontentsline{toc}{chapter}{Abstract und Kurzfassung}
% ****
%

%
% ***
\section*{Abstract}
% ***
%
This bachelor thesis implements a way to achieve a reliable and stable control of a dynamic system through approaches of reinforcement learning. As an example for a neuronal network, the \glqq Touch Withdrawal Circuit\grqq{} of the worm \textit{C. Elegans} is examined in great detail and the structures are transformed into a simulator. As a simulation environment, the inverted pendulum is being used with one degree of freedom (1 DOF). To simulate the neural network and guarantee stabilization of the inverted pendulum, a simulator is being developed and implemented using the programming language \texttt{Python}. Using the well known Leaky Integrate and Fire model, simulation of internal neural dynamics and processing information within the network is made possible. Furthermore, parameters of the network are found using reinforcement learning algorithms and applied to the environment \texttt{CartPole\_v0} from OpenAI Gym. The results of this work show, that it is possible to implement a functional simulator for biological neural networks and to link it with methods of reinforcement learning. After computing multiple simulations, suitable parameters for the network, which ensure stable control of the inverse pendulum, are found. An application to other simulation environments or with similar neural networks is also possible due to the structure of the simulator.


%
% ***
\section*{Kurzfassung}
% ***
%
Ziel dieser Bachelorarbeit ist es, durch Ansätze des Reinforcement Learning, sowie unter Nutzung biologischer neuronaler Netze, eine zuverlässige und stabile Regelung eines dynamischen Systems zu erzielen. Als neuronales Netz wird der sog. \glqq Touch Withdrawal Circuit\grqq{} des Wurms \textit{C. Elegans} detailliert untersucht und die Strukturen in einen Simulator überführt. Als Simulationsumgebung wird das inverse Pendel mit einem Freiheitsgrad gewählt. Um das o.g. neuronale Netz zu simulieren und die Regelung auf das inverse Pendel zu übertragen, wird ein Simulator in der Programmiersprache \texttt{Python} entwickelt und implementiert. Dieser nutzt das bekannte Leaky Integrate and Fire Modell, um die neuronale Dynamik zu simulieren und Prozesse innerhalb des Netzwerkes darzustellen. Parameter des Netzwerkes werden durch Algorithmen des Reinforcement Learning gefunden und auf die Umgebung \texttt{CartPole\_v0} (OpenAI Gym) angewendet. Das Ergebnis dieser Arbeit zeigt, dass es möglich ist, einen funktionsfähigen Simulator für biologische neuronale Netze zu implementieren und diesen mit Methoden des Reinforcement Learning zu koppeln. Durch rechenintensive Simulationen wurden geeignete Parameter für das Netzwerk gefunden, welche eine stabile Regelung des inversen Pendels gewährleisten. Eine Anwendung auf weitere Simulationsumgebungen oder mit ähnlichen neuronalen Netzen ist durch den universalen Aufbau des Simulators ebenfalls möglich.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
