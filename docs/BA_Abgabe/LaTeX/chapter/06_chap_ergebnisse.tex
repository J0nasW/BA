%
% ****
\chapter{Performance \& Auswertung}
\label{chap:erg}
% ****
%
	Dieses Kapitel dient der Auswertung von Versuchsergebnissen und dem Vergleich der verschiedenen Suchalgorithmen. Ausgangspunkt und somit Vergleichskriterium sind Simulationsgrößen des inversen Pendels \texttt{CartPole\_v0} des Frameworks OpenAI Gym.	Es wurde zuerst eine Berechnungsgrundlage eines neuronalen Netzes nach \textit{C. Elegans} \cite{CElegans} geschaffen und implementiert. Dazu wurden verschiedene numerische Lösungsverfahren von Differentialgleichungen verglichen und umgesetzt \cite{NonlinearDynamics}. Letztlich wird ein universeller Simulator geschaffen, welcher Informationen über die Nervenzellen und Synapsen erhält und entsprechend in der Lage ist, das Netz zu simulieren und Feuer-Events auszugeben. Um die Performance des neuronalen Netzes durch den Simulator zu messen, wird eine Simulationsumgebung eingebunden und ein Lern-Algorithmus implementiert. Im Folgenden wird sich auf die \textit{Reinforcement Learning} Methode Random-Search konzentriert, die Methode der genetischen Algorithmen untersucht und auf die Optimierungsmethode durch Gewichten der entsprechenden Synapsen eingegangen.

% ***
\section{Performance implementierter Algorithmen}
\label{sec:erg_performance}
% ***
	Die Schnelligkeit der Ausführung von Algorithmen und ganzen Skripten ist in dieser Anwendung von großer Relevanz. Da der Simulator von Grund auf darauf ausgerichtet worden ist, später rechenintensive Simulationen von Parametern zu durchlaufen, wird bereits in der Auswahl der zusätzlich genutzten Pakete darauf geachtet, diese performant und ressourceneffizient zu implementieren.
	
	Angefangen bei den Berechnungsmodulen in der Datei \texttt{lif.py} wird für komplexere mathematische Operationen die Erweiterung \texttt{NumPy} \cite{NumPy} aus dem bekannten Python-Paket \texttt{SciPy} \cite{NumPy} genutzt. Außerdem werden Schleifen und If-Abfragen ohne Redundanzen und unnötige Befehle implementiert, um in der höheren Abstraktionsebene einen einwandfreien Aufruf zu garantieren. Nach erfolgreichen Tests der implementierten Funktionen ist das Framework für den Simulator erstellt worden. Genutzte Pakete wie \texttt{matplotlib} \cite{Hunter2007} oder \texttt{Hickle} \cite{hdf5} sind ebenfalls für ihre Schnelligkeit und einfache Handhabung ausgewählt worden. Des Weiteren können hier die bereits implementierten Funktionen zur Berechnung von Synapsenströmen und Membranpotentialen einfach importiert werden.
	
	Letztendlich ist die Ausführung der Suchalgorithmen Random-Search und Genetic Algorithm sowie die Optimierung durch den Algorithmus Weights ausschlaggebend. Diese Algorithmen wurden im Laufe der Implementierung immer wieder optimiert und verbessert, sodass eine zuverlässige Simulation mit effizienten Laufzeiten möglich wird. Bei festen Simulationszeiten werden auf der bereits vorgestellten virtuellen Instanz folgende Ergebnisse erzielt (stichprobenartig aufgelistet):
	\begin{table}[H]
		\centering
		\resizebox{0.6\columnwidth}{!}{%
		\begin{tabular}{c@{\hskip 0.5cm}c@{\hskip 0.5cm}c@{\hskip 0.5cm}c}    \toprule
			\setlength{\tabcolsep}{50pt}
			\renewcommand{\arraystretch}{1.5}
			\emph{Zeitstempel}	& \emph{Belohnung} 	& \emph{Laufzeit}	& \emph{Anz. Simulationen} 	\\\midrule
			20180815\_10-40-23  & 26				& 2 Std.			& $39.006$					\\ 
			20180816\_01-50-01	& 123				& 12 Std.			& $10.509.904$				\\
			20180816\_01-52-01	& 185				& 12 Std.			& $10.536.512$				\\
			20180818\_02-48-01	& \textbf{200}		& 12 Std.			& $10.852.326$				\\\bottomrule
			\hline
		\end{tabular}}
	\caption{Parametersuche durch Algorithmus \texttt{Random-Search}.}
	\label{tab:sim_rs}
	\end{table}
	\begin{table}[H]
		\centering
		\resizebox{0.6\columnwidth}{!}{%
		\begin{tabular}{c@{\hskip 0.5cm}c@{\hskip 0.5cm}c@{\hskip 0.5cm}c}    \toprule
			\setlength{\tabcolsep}{50pt}
			\renewcommand{\arraystretch}{1.5}
			\emph{Zeitstempel}	& \emph{Belohnung} 	& \emph{Laufzeit}	& \emph{Anz. Simulationen} 	\\\midrule
			20180815\_11-21-46  & 56				& 1 Std.			& $5.927$					\\ 
			20180816\_13-50-01	& 149				& 12 Std.			& $3.715.008$				\\
			20180816\_13-52-01	& \textbf{200}		& 12 Std.			& $3.686.723$				\\\bottomrule
			\hline
		\end{tabular}}
		\caption{Optimierung durch Algorithmus \texttt{Weights}.}
		\label{tab:sim_weights}
	\end{table}
	Diese Simulationen wurden ausnahmslos auf derselben virtuellen Instanz (parallel) ausgeführt. Die genauen Spezifikationen wurden in Abschnitt \ref{sec:imp_search} bereits detailliert beschrieben. Auffällig ist die unterschiedliche Anzahl an Simulationen bei gleichbleibender Zeit zwischen dem Suchalgorithmus Random-Search und dem Optimierungsalgorithmus Weights. Im Schnitt werden bei der Parametersuche ca. 11 Mio. Simulationen in einem Zeitraum von 12 Stunden erfasst. Die nachgelagerte Optimierung durch den Algorithmus Weights ist jedoch rechenintensiver und erfasst innerhalb 12 Stunden lediglich ca. 3,7 Mio. Simulationen.
	
	Der Suchalgorithmus Genetic Algorithm ist nicht auf lange Simulationszeiten ausgelegt. Durch die zielgerichtete Suche über mehrere Generationen hinweg werden die Grenzen der Gleichverteilung von Parametern aktualisiert und pendeln sich innerhalb weniger Minuten ein (siehe Abbildungen \ref{fig:ga_1} und \ref{fig:ga_2}). Doch wie bereits in Abschnitt \ref{subsec:gen_alg} angedeutet, wird in jedem Simulationslauf lediglich ein lokales Maximum gefunden. Dieses ist nur mit geringer Wahrscheinlichkeit auch das globale Optimum der Simulationsumgebung.
	\begin{table}[H]
		\centering
		\resizebox{0.6\columnwidth}{!}{%
			\begin{tabular}{c@{\hskip 0.5cm}c@{\hskip 0.5cm}c@{\hskip 0.5cm}c}    \toprule
				\setlength{\tabcolsep}{50pt}
				\renewcommand{\arraystretch}{1.5}
				\emph{Zeitstempel}	& \emph{Belohnung} 	& \emph{Laufzeit}	& \emph{Anz. Simulationen} 	\\\midrule
				20180905\_10-12-08  & 11				& 10 Min			& $253.416$					\\ 
				20180905\_10-22-08	& \textbf{200}		& 10 Min			& $276.505$				\\
				20180905\_11-22-08	& 31				& 10 Min			& $295.116$				\\\bottomrule
				\hline
		\end{tabular}}
		\caption{Optimierung durch Algorithmus \texttt{Genetic\_Algorithm}.}
		\label{tab:sim_gen}
	\end{table}
	Wie der Tabelle \ref{tab:sim_gen} zu entnehmen ist, ergeben Simulationen gleicher Dauer stark divergente Reward-Ergebnisse.\\
	Letztendlich zeigen diese Daten, dass die implementierten Algorithmen in der Lage sind, dauerhafte Simulationen mit guten Ergebnissen zu erzielen. Durch kleinere Verbesserungen und Veränderungen am Code erzielte der Parametersuchlauf mit dem Zeitstempel \texttt{20180818\_02-48-01} das erste Mal eine Belohnung von 200. Dieses Ergebnis beweist die Funktionsweise des Simulators und hält das Pendel in 200 von 200 Simulationsschritten erfolgreich aufrecht. Eine Animation dieser Parameter wird in Appendix \ref{app:parameter} genauer erläutert und veranschaulicht.
	
% ***
\section{Limitationen und Alternativen von Algorithmen}
\label{sec:erg_lim}
% ***
	Die bereits vorgestellten Algorithmen \texttt{Random-Search} als Such- und \texttt{Weights} als Optimierungsalgorithmus führen zwar mit viel Rechenleistung und hohen Simulationszeiten zu guten und verlässlichen Ergebnissen, sind jedoch im Grunde ineffizient. Einzig die Herangehensweise durch genetische Algorithmen ist nicht sehr rechenintensiv, liefert jedoch durch die zielgerichtete Suche meist ein lokales Maximum an Belohnung, welches gering ausfällt.\\
	\subsection{Analyse bereits bestehender Algorithmen}
		\texttt{Random-Search} generiert Vektoren mit zufälligen Parametern innerhalb einer gegebenen Gleichverteilung und wendet diese auf die Simulationsumgebung an. Die Belohnung am Ende einer jeden Simulation sagt etwas über die Güte dieser generierten Parameter aus. Ist die Belohnung hoch, so werden die Parameter gespeichert, fällt die Belohnung geringer als die bisher beste Belohnung aus, wird diese Simulation verworfen. So baut sich ein High-Score-System auf und nach Ablauf der Simulationszeit werden die Parameter mit der höchsten erreichten Belohnung gespeichert.	Wie darüber hinaus in Abbildung \ref{fig:uml_rs} noch einmal verdeutlicht, werden gute Parameter für stabile Simulationsläufe durch den simplen Input der Belohnung gefunden.
		
		Analog zu \texttt{Random-Search} beginnt der Algorithmus \texttt{Genetic Algorithm} mit zufälligen Parametern in gegebenen Grenzen. Nach einer festen Anzahl an Episoden ist eine Generation vollendet und wird untersucht. Maxima und Minimal der Parameter werden isoliert und als neue Grenzen der Gleichverteilung für zufällige Parameter gesetzt. Ein High-Score-System ermittelt wieder die besten Simulationen und entsprechende Parameter werden gespeichert.
		
		Nach Anwendung der Parametersuche durch \texttt{Random-Search} oder \texttt{Genetic Algorithm} wird eine Optimierung des neuronalen Netzes durch den Optimierungsalgorithmus \texttt{Weights} durchgeführt. Durch das Einführen von Gewichten für Synapsen und Gap-Junctions, können gewisse Informationsbahnen eingestellt und die Simulation weiter verbessert werden. In Abbildung \ref{fig:uml_weights} wird der gesamte Programmablauf noch einmal verdeutlicht.	Gefundene Parameter und Gewichte guter Simulationsläufe werden in Appendix \ref{app:parameter} aufgeführt.
		
		Aufgrund der starken Symmetrie des gegebenen Problems und des neuronalen Netzes ist es darüber hinaus möglich, eine symmetrische Parameter- und Gewichtsgenerierung zu implementieren. Anstatt der gesamten 46 Parameter für Nervenzellen Synapsen und Gap-Junctions, werden jeweils nur die Hälfte der benötigten Parameter generiert und anschließend dupliziert. Dies sorgt für eine symmetrische Verteilung von zufällig generierten Parametern und einer noch effizienteren Simulation. Aufgrund der symmetrischen Architektur des gegebenen neuronalen Netzes ist diese Methode zulässig und führt zu sehr guten Ergebnissen.
	\subsection{Alternative Such- und Optimierungsalgorithmen}
		Wie bereits in Abschnitt \ref{sec:rl_alt} vorgestellt, existieren bereits viele gute Algorithmen zur Parametersuche und -optimierung von künstlich erzeugten oder gegebenen neuronalen Netzen. Doch die Implementierung dieser Algorithmen, besonders auf die hohe Anzahl an zu variierenden Parametern, stellt eine erweiterte Anforderung dar.
		
		Der in Abschnitt \ref{subsec:rl_qlearning} zuerst vorgestellte Algorithmus des Q-Learning ist speziell für die neuen Praktiken der künstlich erschaffenen neuronalen Netze entwickelt worden. Hier wird auf die Gewichtung vieler einfacher Verbindungen zwischen Neuronen unterschiedlicher Ebenen fokussiert. Die Grundlagen könnten auf einfache Parameteroptimierungen angewendet werden, jedoch ist dieser Aspekt größtenteils unerforscht.
		
		Die Methode, durch Gradient Policies eine Parameteroptimierung durchzuführen, ist durchaus möglich und kann zu effizienteren Simulationslaufzeiten führen. Problematisch ist aber die Tatsache, dass sich durch die Anzahl an zu simulierenden Parametern viele lokale Maxima in der Belohnungs-Funktion bilden und somit der Algorithmus schnell zu einem Ende kommt. Die grundsätzliche Vorgehensweise beginnt analog zu Random-Search mit einer zufälligen Generierung von Parametern und einem ersten Simulationslauf. Nach der ersten Episode wird ein weiterer, zufälliger Parametersatz generiert und eine zweite Simulation initiiert. Ist die Belohnung dieser zweiten Episode höher, werden die Parameter entsprechend verglichen und die Grenzen zur Generierung neuer, zufälliger Parameter für die nächsten Episoden aktualisiert.
		
		Die dritte Herangehensweise der genetischen Algorithmen stellt sich als robustere Methode im Vergleich zu Gradient Policies heraus. Durch die Wahl mehrerer Simulationsläufe mit guten Belohnungen und die Expansion dieser Selektion (als Mutation) durch Varianzen wird ebenfalls zielgerichteter gesucht und die Chance, ein globales Optimum zu finden, erhöht. Da die Implementierung dieser Methode jedoch um ein vielfaches komplexer ist und weitere Parameter liefert, welche es zu optimieren gilt, fallen im aktuellen Stadium die Belohnungen meist gering aus. Nur wenige Ausnahmen liefern Belohnungen bis hin zu $200/200$.
		
		Einzig die Optimierung durch Gewichtung von Synapsen und Gap-Junctions kann mit bekannten Algorithmen und dem Input des Rewards das Ergebnis effizient und verlässlich beeinflussen.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
